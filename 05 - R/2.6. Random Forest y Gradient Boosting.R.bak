set.seed(500) # Utilizamos este comando para que los resultados aleatorios sean siempre los mismos

# Carga de datos
library(MASS)
data <- Boston

# División train-test
index <- sample(1:nrow(data),round(0.80*nrow(data)))
train <- data[index,]
test <- data[-index,]


# RANDOM FOREST
library(randomForest)
rf <- randomForest(medv~., data=train,ntree=500)
pr.rf <- predict(rf,test)
MSE.rf <- sum((pr.rf - test$medv)^2)/nrow(test)
print(MSE.rf) 
error_porcentaje.rf = 100*mean((pr.rf-test$medv)/test$medv)
print(error_porcentaje.rf) 
plot(test$medv,pr.rf)
abline(0,1,col="red")
cor(test$medv,pr.rf)^2 # R^2 

# GBM
library(caret)
# CrossValidation
ctrl <- trainControl(method = "repeatedcv", 
                     number = 10, repeats = 3, 
                     allowParallel= T)

modelGBM <- train(medv~., data=train, method="gbm", trControl=ctrl,verbose=F)

modelGBM
# El siguiente plot indica los mejores hiperparámetros del modelo
plot(modelGBM)
# Predicción
pr.gb <- predict(modelGBM,test)
MSE.gb <- sum((pr.gb - test$medv)^2)/nrow(test)
print(MSE.gb) 
error_porcentaje.gb = 100*mean((pr.gb-test$medv)/test$medv)
print(error_porcentaje.gb)
plot(test$medv,pr.gb)
abline(0,1,col="red")
cor(test$medv,pr.gb)
